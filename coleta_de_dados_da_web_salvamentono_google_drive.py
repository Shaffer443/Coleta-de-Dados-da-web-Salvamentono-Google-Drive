# -*- coding: utf-8 -*-
"""Coleta de Dados da web-Salvamentono Google Drive

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S-26zVMIcX6wmWjFdnD6DyKa_pzK592l

**Coletada de dados web com python**

instalações:

- pip install requests </br>
- pip install Beautifulsoup4 (! pip install beautifulsoup4) </br></br>

links uteis: <br>
https://acervolima.com/instalacao-do-beautifulsoup-python/ </br>
https://www.youtube.com/watch?v=QzD86JyeKXE </br>
https://www.crummy.com/software/BeautifulSoup/bs4/doc.ptbr/ </br>
https://algoritmosempython.com.br/cursos/programacao-python/strings/

**Google Colab e Planilha google integrados**

link: https://www.youtube.com/watch?v=YaCeqXpxWUk

<mark>Instalando gspread:</mark>

!pip install gspread

<mark>Importando as bibliotecas:</mark>

from google.colab import auth </br>
from oauth2client.client import GoogleCredentials

<mark> precisei instalar</mark> </br>
!pip install selenium

extras:

https://stackoverflow.com/questions/71686960/typeerror-credentials-need-to-be-from-either-oauth2client-or-from-google-auth </br>

https://github.com/burnash/gspread/issues/1014#issuecomment-1082536016

**Documentação**

https://docs.gspread.org/en/latest/
"""

#instaladores:

!pip install selenium

# biblioteca:

import requests
import gspread
import selenium
import pandas as pd

# rodou assim sem instalar

from bs4 import BeautifulSoup
from google.colab import auth 
from google.auth import default
creds, _ = default()
# from oauth2client.client import GoogleCredentials

#Teste

from selenium import webdriver
#from selenium.webdriver.common.keys import by
from selenium.webdriver.common.by import By

# solicitando autenticação:
# vai gerar uma autenticação e uma senha para validação

auth.authenticate_user()

gc = gspread.authorize(creds)

#criando planilha

gc.create('DadosTorneio')

# main:

site = requests.get("https://www.soccerstats.com/latest.asp?league=england")
site.encoding='utf-8' # deixar no padrão utf-8
soup = BeautifulSoup(site.text, 'html.parser') # faz com que o entenda o texto do site (site.text) como os objetos incluidos de html
                                                # podemos pegar as tags do site 
tabelageral = soup.find_all(class_="trow3") # encontrar tudo (find_all), passar o parâmetro om o obejeto e nome dado a ele, restornando em array
                                            #exemplo: cotacaoodds = soup.find_all(class_="trow3") 
                                            # um filtro de tags que nos interessa na busca
                                            #find_all == encontra todos os atributos | find = o primeiro que encontrar

#teste:

#link = requests.get("<b>76%</b>")

#porcentagem = site.find_element(By.XPATH,'/html/body/div[1]/div[2]/table[2]/tbody/tr/td/table[1]/tbody/tr/td[2]/table/tbody/tr[1]/b').get_attribute("name")

#print(link)

 #fim do teste#                                           

dadosgerais=[]
#porcentagem=[]
for dados in tabelageral: # varrendo dados
  #print(dados.find('td')) # filtrando a varredura por uma tag
  #indicador = dados.find("td")
  #porc = indicador.b.text
  info = dados.find_all("b")
  #conteudo = dados.b.string
  #percentual = info.b.text
  dadosgerais.append(info)
  #porcentagem.append(conteudo)
  #dadosgerais.append(conteudo)

#print("{}".split(dadosgerais[2]))


teste = dadosgerais[2]
tirandodalista = teste[-1] # tirando da lista
print("{} - {}".format(teste, tirandodalista))
print(len(tirandodalista)) # problema é que está não como uma string e sim um unico dado
print(len(teste))

print(dadosgerais[2])  #jogos jogados
print(dadosgerais[5])  #pegando win - over 1,5
print(dadosgerais[6])  #pegando draw - over 2,5
print(dadosgerais[7])  #pegando red - over 3,5
print(dadosgerais[8])  #Goals totais: - Home goals per match: 
print(dadosgerais[9])  #Goals per match: - Away goals per match:  	
print(dadosgerais[10]) # Ambos marcam

##abrir = gc.open('planilhateste')
##salvando = abrir.get_worksheet(0)

#salvando.update_acell('c4',"testando salvamento de dados") 
#salvando.update_acell('c5', "{}".format(conteudo))
#salvando.update_acell('c7', "{}".format(dadosgerais[2]))
#salvando.update_acell('c5',dadosgerais[2]) # não está pegando a lista para salvar
#salvando.update_acell('c6',dadosgerais[5])
#salvando.update_acell('c7',dadosgerais[6])
#salvando.update_acell('c8',dadosgerais[7])
#salvando.update_acell('c9',dadosgerais[8])
#salvando.update_acell('c10',dadosgerais[9])
#salvando.update_acell('c11',dadosgerais[10])



#  escrever.write(" Partidas jogadas: {}".format(dadosgerais[2]))

#escrever.clese()
#print(tabelageral) # podemos passar a array [0] ou [1] ou [2], etc. rerferente ao nosso class alvo
                    # print(cotacaoodds[1])
#print(soup)

# print(site.text) #mostra todo html do site em texto

# print(site) # print q informa a resposta,se há ou não conexão. Se a resposta for <200> significa q esta conseguindo acessar o link

#Data Frame:

#Tabela pré contagem:

#dt=pd.DataFrame(tabelageral)
#print(dt)
#print(dt.columns)

#Tabela Pró Contagem:

dtpos=pd.DataFrame(dadosgerais)
#print(dtpos)
#print("\n")
#print(dtpos.head)
#print("\n\n")

novaselecao = pd.DataFrame({0:'Jogos do Torneio', 1:'Casa Ganha', 2:'Over 1,5', 
                            3:'Empates', 4:'Over 2,5', 5:'Visitante Ganha', 
                            6:'Over 3,5', 7:'Total de Gols', 8:'Gols por jogo - Casa', 
                            9:'Gols por Jogo', 10:'Gols por Jogo - Visitante', 11:'Ambos Marcam'},index =[0])

dfselect = pd.concat([novaselecao,dtpos]).reset_index(drop = True)
#print(dfselect)
print("\n\n")
newdados= dfselect.head(3)
print(newdados)
print("\n\n")
#print(dfselect.columns)

#Colocando dados do data frame em uma variável

#loc = linhas
#iloc= coluna

#-----------------------------------
#coluna 0 - Linha 2 (total de jogos do torneio)

one = newdados.loc[0,0] 
one2 = newdados.loc[2,0]
trans_one2 = list(one2)
f_one2=trans_one2[0]

#-----------------------------------
#coluna 1 - Linha 2 ( Casa Ganha)

two = newdados.loc[0,1] 
two2 = newdados.loc[2,1]
trans_two2 = list(two2)
f_two2=trans_two2[0]


#-----------------------------------
#coluna 2 - Linha 2 (Over 1,5)

tree = newdados.loc[0,2] 
tree2 = newdados.loc[2,2]
trans_tree2 = list(tree2)
f_tree2=trans_tree2[0]

#-----------------------------------
#coluna 3 - Linha 2 (Empates)

four = newdados.loc[0,3] 
four2 = newdados.loc[2,3]
trans_four2 = list(four2)
f_four2=trans_four2[0]

#-----------------------------------
#coluna 4 - Linha 2 (Over 2,5)

five = newdados.loc[0,4] 
five2 = newdados.loc[2,4]
trans_five2 = list(five2)
f_five2=trans_five2[0]

#-----------------------------------
#coluna 5 - Linha 2 (Visitante Ganha)

six = newdados.loc[0,5] 
six2 = newdados.loc[2,5]
trans_six2 = list(six2)
f_six2=trans_six2[0]

#-----------------------------------
#coluna 6 - Linha 2 (Over 3,5)

seven = newdados.loc[0,6] 
seven2 = newdados.loc[2,6]
trans_seven2 = list(seven2)
f_seven2=trans_seven2[0]

#-----------------------------------
#coluna 7 - Linha 2 (Total Gols Torneios)

eight = newdados.loc[0,7] 
eight2 = newdados.loc[2,7]
trans_eight2 = list(eight2)
f_eight2=trans_eight2[0]

#-----------------------------------
#coluna 8 - Linha 2 (Média - Gols Time da Casa)

nine = newdados.loc[0,8] 
nine2 = newdados.loc[2,8]
trans_nine2 = list(nine2)
f_nine2=trans_nine2[0]

#-----------------------------------
#coluna 9 - Linha 2 (Média Gols por jogo)

ten = newdados.loc[0,9] 
ten2 = newdados.loc[2,9]
trans_ten2 = list(ten2)
f_ten2=trans_ten2[0]


#-----------------------------------
#coluna 10 - Linha 2 (Média - Gols Time da Visitante)

eleven = newdados.loc[0,10] 
eleven2 = newdados.loc[2,10]
trans_eleven2 = list(eleven2)
f_eleven2=trans_eleven2[0]

#-----------------------------------
#coluna 11 - Linha 2 (Ambos Marcam)

twelve = newdados.loc[0,11] 
twelve2 = newdados.loc[2,11]
trans_twelve2 = list(twelve2)
f_twelve2=trans_twelve2[0]

#-----------------------------------

#print(twelve)
#print(f_twelve2)

#Salvar no Google Drive:

abrir = gc.open('DadosTorneio').sheet1

abrir.update('A1', "Premier League - Temporada 22/23")
abrir.update('A3',[[one, two, four, six, tree, five, seven, twelve, eight, ten, nine, eleven],
                   [f_one2, f_two2, f_four2, f_six2, f_tree2, f_five2,f_seven2, f_twelve2, f_eight2, f_ten2, f_nine2, f_eleven2]])


#salvando2 = abrir.gc.update('A1', newdados)
#salvando = abrir.get_worksheet(newdados)
#salvando = abrir.get_worksheet(0)

"""/html/body/div[1]/div[2]/table[2]/tbody/tr/td/table[1]/tbody/tr/td[2]/table/tbody/tr[1]/td[5]/b"""